{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 379s 2us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (10000, 32, 32, 3), (50000, 1), (10000, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), dtype('float32'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 225.0\n",
    "X_train.dtype, X_test.dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Explanation**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Conv2D layer** is a 2D convolution layer that applies a `set of filters` to the input image. Each filter is a small matrix that slides over the image and computes a `dot product` between the filter values and the pixel values. The result is a new image (called a `feature map`) that highlights the features that the filter is designed to detect. For example, some filters may **detect edges, corners, colors, textures**, etc. The Conv2D layer can have multiple filters, each producing a different feature map. The layer also has some parameters that control how the filters are applied, such as:\n",
    "\n",
    "- `filters`: the number of filters (or output channels) in the layer.\n",
    "- `kernel_size`: the size of each filter (or kernel) in the layer. It can be a single integer or a tuple of two - integers for height and width.\n",
    "- `strides`: the number of pixels that the filter moves by in each dimension. It can be a single integer or a tuple of two integers for vertical and horizontal strides.\n",
    "- `padding`: how to handle the edges of the input image. It can be either “valid” or “same”. **“valid”** means no padding is added and the output size may be smaller than the input size. **“same”** means padding is added such that the output size is the same as the input size.\n",
    "- `activation`: an optional function to apply to the output of the layer, such as “relu”, “sigmoid”, “tanh”, etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **MaxPooling2D layer** is a 2D pooling layer that **reduces the size of the input image** by taking the maximum value over a window of pixels. This helps to reduce noise, increase speed, and extract dominant features from the image. The MaxPooling2D layer also has some parameters that control how the pooling is done, such as:\n",
    "\n",
    "- `pool_size`: the size of the window over which to take the maximum. It can be a single integer or a tuple of two integers for height and width.\n",
    "- `strides`: the number of pixels that the window moves by in each dimension. It can be a single integer or a tuple of two integers for vertical and horizontal strides. If None, it defaults to pool_size.\n",
    "- `padding`: how to handle the edges of the input image. It can be either “valid” or “same”. “valid” means no padding is added and the output size may be smaller than the input size. “same” means padding is added such that the output size is the same as the input size."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to calculate the ouput size after applying convolution?**\n",
    "\n",
    "output_size = (input_size - kernel_size + 2 * padding) / stride + 1 = (32 - 3 + 2 * 0) / 1 + 1 = 30\n",
    "\n",
    "- padding = `valid` -> padding = 0\n",
    "- padding = `same`  -> padding = (kernel_size - 1) / 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                131136    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cifar10 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(32,32,3)), \n",
    "        layers.Conv2D(32, 3, padding='valid', activation='relu'), # 32 filters, each with kernel of size (3,3)\n",
    "        layers.MaxPooling2D(pool_size=(2,2)), # Each pixel in this feature map represents the maximum value in a 2x2 region of the input feature map.\n",
    "        layers.Conv2D(64, 3, activation='relu'), # 64 filters, each with kernel of size (3,3)\n",
    "        layers.MaxPooling2D(), # pool_size=(2,2) by default\n",
    "        layers.Conv2D(128, 3, activation='relu'), # 128 filters, each with kernel of size (3,3)\n",
    "        layers.Flatten(), # reshape the input feature map into a one-dimensional vector -> prepare the input for the dense layers\n",
    "        layers.Dense(64, activation='relu'), # A Dense layer with 64 units\n",
    "        layers.Dense(10), # computes a linear transformation\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_cifar10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 - 96s - loss: 1.7859 - accuracy: 0.3507 - 96s/epoch - 123ms/step\n",
      "Epoch 2/10\n",
      "782/782 - 70s - loss: 1.4511 - accuracy: 0.4807 - 70s/epoch - 89ms/step\n",
      "Epoch 3/10\n",
      "782/782 - 70s - loss: 1.3038 - accuracy: 0.5375 - 70s/epoch - 89ms/step\n",
      "Epoch 4/10\n",
      "782/782 - 72s - loss: 1.1912 - accuracy: 0.5819 - 72s/epoch - 92ms/step\n",
      "Epoch 5/10\n",
      "782/782 - 74s - loss: 1.1045 - accuracy: 0.6145 - 74s/epoch - 95ms/step\n",
      "Epoch 6/10\n",
      "782/782 - 75s - loss: 1.0319 - accuracy: 0.6400 - 75s/epoch - 96ms/step\n",
      "Epoch 7/10\n",
      "782/782 - 73s - loss: 0.9715 - accuracy: 0.6617 - 73s/epoch - 94ms/step\n",
      "Epoch 8/10\n",
      "782/782 - 73s - loss: 0.9162 - accuracy: 0.6827 - 73s/epoch - 94ms/step\n",
      "Epoch 9/10\n",
      "782/782 - 74s - loss: 0.8677 - accuracy: 0.6997 - 74s/epoch - 95ms/step\n",
      "Epoch 10/10\n",
      "782/782 - 74s - loss: 0.8201 - accuracy: 0.7172 - 74s/epoch - 95ms/step\n",
      "157/157 - 5s - loss: 0.9981 - accuracy: 0.6574 - 5s/epoch - 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9981285333633423, 0.6574000120162964]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model compile\n",
    "model_cifar10.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.experimental.RMSprop(\n",
    "        learning_rate=3e-4,\n",
    "    ),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model_cifar10.fit(X_train, y_train, batch_size=64, epochs=10, verbose=2)\n",
    "model_cifar10.evaluate(X_test, y_test, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model_cifar10, open('model_cifar10.pickle', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Functional API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 - 325s - loss: 2.6468 - accuracy: 0.1069 - 325s/epoch - 416ms/step\n",
      "Epoch 2/10\n",
      "782/782 - 312s - loss: 2.2558 - accuracy: 0.1316 - 312s/epoch - 399ms/step\n",
      "Epoch 3/10\n",
      "782/782 - 292s - loss: 1.9447 - accuracy: 0.2652 - 292s/epoch - 374ms/step\n",
      "Epoch 4/10\n",
      "782/782 - 290s - loss: 1.5111 - accuracy: 0.4449 - 290s/epoch - 370ms/step\n",
      "Epoch 5/10\n",
      "782/782 - 335s - loss: 1.3068 - accuracy: 0.5290 - 335s/epoch - 428ms/step\n",
      "Epoch 6/10\n",
      "782/782 - 310s - loss: 1.2044 - accuracy: 0.5660 - 310s/epoch - 397ms/step\n",
      "Epoch 7/10\n",
      "782/782 - 309s - loss: 1.1284 - accuracy: 0.5955 - 309s/epoch - 395ms/step\n",
      "Epoch 8/10\n",
      "782/782 - 319s - loss: 1.0818 - accuracy: 0.6110 - 319s/epoch - 408ms/step\n",
      "Epoch 9/10\n",
      "782/782 - 274s - loss: 1.0345 - accuracy: 0.6299 - 274s/epoch - 350ms/step\n",
      "Epoch 10/10\n",
      "782/782 - 316s - loss: 0.9953 - accuracy: 0.6444 - 316s/epoch - 404ms/step\n",
      "157/157 - 19s - loss: 1.1086 - accuracy: 0.6127 - 19s/epoch - 120ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.108610987663269, 0.6126999855041504]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_model():\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "    \n",
    "    x = layers.Conv2D(32,3)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, 5, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, 3)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    outputs = layers.Dense(10)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "model_cifar10_2 = my_model()\n",
    "model_cifar10_2.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.experimental.Adam(\n",
    "        learning_rate=0.01,\n",
    "    ),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model_cifar10_2.fit(X_train, y_train, batch_size=64, epochs=10, verbose=2)\n",
    "model_cifar10_2.evaluate(X_test, y_test, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\batch_normalization\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      ".........3\n",
      "...layers\\batch_normalization_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      ".........3\n",
      "...layers\\batch_normalization_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      ".........3\n",
      "...layers\\conv2d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\input_layer\n",
      "......vars\n",
      "...layers\\max_pooling2d\n",
      "......vars\n",
      "...layers\\tf_op_lambda\n",
      "......vars\n",
      "...layers\\tf_op_lambda_1\n",
      "......vars\n",
      "...layers\\tf_op_lambda_2\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........29\n",
      ".........3\n",
      ".........30\n",
      ".........31\n",
      ".........32\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-27 03:06:14         7245\n",
      "metadata.json                                  2023-04-27 03:06:14           64\n",
      "variables.h5                                   2023-04-27 03:06:14     18197560\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(model_cifar10_2, open('model_cifar10_2.pickle', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
